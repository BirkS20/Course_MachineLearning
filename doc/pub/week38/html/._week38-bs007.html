<!--
Automatically generated HTML file from DocOnce source
(https://github.com/doconce/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Data Analysis and Machine Learning: Logistic Regression">

<title>Data Analysis and Machine Learning: Logistic Regression</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plans for week 38', 2, None, 'plans-for-week-38'),
              ('Ridge and LASSO Regression, reminder',
               2,
               None,
               'ridge-and-lasso-regression-reminder'),
              ('Various steps in cross-validation',
               2,
               None,
               'various-steps-in-cross-validation'),
              ('How to set up the cross-validation for Ridge and/or Lasso',
               2,
               None,
               'how-to-set-up-the-cross-validation-for-ridge-and-or-lasso'),
              ('Cross-validation in brief',
               2,
               None,
               'cross-validation-in-brief'),
              ('Code Example for Cross-validation and $k$-fold '
               'Cross-validation',
               2,
               None,
               'code-example-for-cross-validation-and-k-fold-cross-validation'),
              ('To think about', 2, None, 'to-think-about'),
              ('More complicated Example: The Ising model',
               2,
               None,
               'more-complicated-example-the-ising-model'),
              ('Reformulating the problem to suit regression',
               2,
               None,
               'reformulating-the-problem-to-suit-regression'),
              ('Linear regression', 2, None, 'linear-regression'),
              ('Singular Value decomposition',
               2,
               None,
               'singular-value-decomposition'),
              ('The one-dimensional Ising model',
               2,
               None,
               'the-one-dimensional-ising-model'),
              ('Ridge regression', 2, None, 'ridge-regression'),
              ('LASSO regression', 2, None, 'lasso-regression'),
              ('Performance as  function of the regularization parameter',
               2,
               None,
               'performance-as-function-of-the-regularization-parameter'),
              ('Finding the optimal value of $\\lambda$',
               2,
               None,
               'finding-the-optimal-value-of-lambda'),
              ('Logistic Regression', 2, None, 'logistic-regression'),
              ('Classification problems', 2, None, 'classification-problems'),
              ('Optimization and Deep learning',
               2,
               None,
               'optimization-and-deep-learning'),
              ('Basics', 2, None, 'basics'),
              ('Linear classifier', 2, None, 'linear-classifier'),
              ('Some selected properties', 2, None, 'some-selected-properties'),
              ('Simple example', 2, None, 'simple-example'),
              ('Plotting the mean value for each group',
               2,
               None,
               'plotting-the-mean-value-for-each-group'),
              ('The logistic function', 2, None, 'the-logistic-function'),
              ('Examples of likelihood functions used in logistic regression '
               'and nueral networks',
               2,
               None,
               'examples-of-likelihood-functions-used-in-logistic-regression-and-nueral-networks'),
              ('Two parameters', 2, None, 'two-parameters'),
              ('Maximum likelihood', 2, None, 'maximum-likelihood'),
              ('The cost function rewritten',
               2,
               None,
               'the-cost-function-rewritten'),
              ('Minimizing the cross entropy',
               2,
               None,
               'minimizing-the-cross-entropy'),
              ('A more compact expression',
               2,
               None,
               'a-more-compact-expression'),
              ('Extending to more predictors',
               2,
               None,
               'extending-to-more-predictors'),
              ('Including more classes', 2, None, 'including-more-classes'),
              ('More classes', 2, None, 'more-classes'),
              ('Wisconsin Cancer Data', 2, None, 'wisconsin-cancer-data'),
              ('Using the correlation matrix',
               2,
               None,
               'using-the-correlation-matrix'),
              ('Discussing the correlation data',
               2,
               None,
               'discussing-the-correlation-data'),
              ('Other measures in classification studies: Cancer Data  again',
               2,
               None,
               'other-measures-in-classification-studies-cancer-data-again')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week38-bs.html">Data Analysis and Machine Learning: Logistic Regression</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week38-bs001.html#plans-for-week-38" style="font-size: 80%;">Plans for week 38</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs002.html#ridge-and-lasso-regression-reminder" style="font-size: 80%;">Ridge and LASSO Regression, reminder</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs003.html#various-steps-in-cross-validation" style="font-size: 80%;">Various steps in cross-validation</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs004.html#how-to-set-up-the-cross-validation-for-ridge-and-or-lasso" style="font-size: 80%;">How to set up the cross-validation for Ridge and/or Lasso</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs005.html#cross-validation-in-brief" style="font-size: 80%;">Cross-validation in brief</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs006.html#code-example-for-cross-validation-and-k-fold-cross-validation" style="font-size: 80%;">Code Example for Cross-validation and \( k \)-fold Cross-validation</a></li>
     <!-- navigation toc: --> <li><a href="#to-think-about" style="font-size: 80%;">To think about</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs008.html#more-complicated-example-the-ising-model" style="font-size: 80%;">More complicated Example: The Ising model</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs009.html#reformulating-the-problem-to-suit-regression" style="font-size: 80%;">Reformulating the problem to suit regression</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs010.html#linear-regression" style="font-size: 80%;">Linear regression</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs011.html#singular-value-decomposition" style="font-size: 80%;">Singular Value decomposition</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs012.html#the-one-dimensional-ising-model" style="font-size: 80%;">The one-dimensional Ising model</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs013.html#ridge-regression" style="font-size: 80%;">Ridge regression</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs014.html#lasso-regression" style="font-size: 80%;">LASSO regression</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs015.html#performance-as-function-of-the-regularization-parameter" style="font-size: 80%;">Performance as  function of the regularization parameter</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs016.html#finding-the-optimal-value-of-lambda" style="font-size: 80%;">Finding the optimal value of \( \lambda \)</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs017.html#logistic-regression" style="font-size: 80%;">Logistic Regression</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs018.html#classification-problems" style="font-size: 80%;">Classification problems</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs019.html#optimization-and-deep-learning" style="font-size: 80%;">Optimization and Deep learning</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs020.html#basics" style="font-size: 80%;">Basics</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs021.html#linear-classifier" style="font-size: 80%;">Linear classifier</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs022.html#some-selected-properties" style="font-size: 80%;">Some selected properties</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs023.html#simple-example" style="font-size: 80%;">Simple example</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs024.html#plotting-the-mean-value-for-each-group" style="font-size: 80%;">Plotting the mean value for each group</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs025.html#the-logistic-function" style="font-size: 80%;">The logistic function</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs026.html#examples-of-likelihood-functions-used-in-logistic-regression-and-nueral-networks" style="font-size: 80%;">Examples of likelihood functions used in logistic regression and nueral networks</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs027.html#two-parameters" style="font-size: 80%;">Two parameters</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs028.html#maximum-likelihood" style="font-size: 80%;">Maximum likelihood</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs029.html#the-cost-function-rewritten" style="font-size: 80%;">The cost function rewritten</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs030.html#minimizing-the-cross-entropy" style="font-size: 80%;">Minimizing the cross entropy</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs031.html#a-more-compact-expression" style="font-size: 80%;">A more compact expression</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs032.html#extending-to-more-predictors" style="font-size: 80%;">Extending to more predictors</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs033.html#including-more-classes" style="font-size: 80%;">Including more classes</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs034.html#more-classes" style="font-size: 80%;">More classes</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs035.html#wisconsin-cancer-data" style="font-size: 80%;">Wisconsin Cancer Data</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs036.html#using-the-correlation-matrix" style="font-size: 80%;">Using the correlation matrix</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs037.html#discussing-the-correlation-data" style="font-size: 80%;">Discussing the correlation data</a></li>
     <!-- navigation toc: --> <li><a href="._week38-bs038.html#other-measures-in-classification-studies-cancer-data-again" style="font-size: 80%;">Other measures in classification studies: Cancer Data  again</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0007"></a>
<!-- !split -->

<h2 id="to-think-about" class="anchor">To think about </h2>

<p>
When you are comparing your own code with for example <b>Scikit-Learn</b>'s library, there are some minor things to keep in mind.
The example here shows how one can keep the intercept in order to compare own code.

<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%;"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">pandas</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">pd</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.model_selection</span> <span style="color: #008000; font-weight: bold">import</span> train_test_split
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn</span> <span style="color: #008000; font-weight: bold">import</span> linear_model

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">R2</span>(y_data, y_model):
    <span style="color: #008000; font-weight: bold">return</span> <span style="color: #666666">1</span> <span style="color: #666666">-</span> np<span style="color: #666666">.</span>sum((y_data <span style="color: #666666">-</span> y_model) <span style="color: #666666">**</span> <span style="color: #666666">2</span>) <span style="color: #666666">/</span> np<span style="color: #666666">.</span>sum((y_data <span style="color: #666666">-</span> np<span style="color: #666666">.</span>mean(y_data)) <span style="color: #666666">**</span> <span style="color: #666666">2</span>)
<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">MSE</span>(y_data,y_model):
    n <span style="color: #666666">=</span> np<span style="color: #666666">.</span>size(y_model)
    <span style="color: #008000; font-weight: bold">return</span> np<span style="color: #666666">.</span>sum((y_data<span style="color: #666666">-</span>y_model)<span style="color: #666666">**2</span>)<span style="color: #666666">/</span>n


<span style="color: #408080; font-style: italic"># A seed just to ensure that the random numbers are the same for every run.</span>
<span style="color: #408080; font-style: italic"># Useful for eventual debugging.</span>
np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>seed(<span style="color: #666666">3155</span>)

n <span style="color: #666666">=</span> <span style="color: #666666">100</span>
x <span style="color: #666666">=</span> np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>rand(n)
y <span style="color: #666666">=</span> np<span style="color: #666666">.</span>exp(<span style="color: #666666">-</span>x<span style="color: #666666">**2</span>) <span style="color: #666666">+</span> <span style="color: #666666">1.5</span> <span style="color: #666666">*</span> np<span style="color: #666666">.</span>exp(<span style="color: #666666">-</span>(x<span style="color: #666666">-2</span>)<span style="color: #666666">**2</span>)

Maxpolydegree <span style="color: #666666">=</span> <span style="color: #666666">20</span>
X <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((n,Maxpolydegree))
X[:,<span style="color: #666666">0</span>] <span style="color: #666666">=</span> <span style="color: #666666">1.0</span>

<span style="color: #008000; font-weight: bold">for</span> polydegree <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #666666">1</span>, Maxpolydegree):
    <span style="color: #008000; font-weight: bold">for</span> degree <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(polydegree):
        X[:,degree] <span style="color: #666666">=</span> x<span style="color: #666666">**</span>degree


<span style="color: #408080; font-style: italic"># We split the data in test and training data</span>
X_train, X_test, y_train, y_test <span style="color: #666666">=</span> train_test_split(X, y, test_size<span style="color: #666666">=0.2</span>)

<span style="color: #408080; font-style: italic"># matrix inversion to find beta</span>
OLSbeta <span style="color: #666666">=</span> np<span style="color: #666666">.</span>linalg<span style="color: #666666">.</span>pinv(X_train<span style="color: #666666">.</span>T <span style="color: #666666">@</span> X_train) <span style="color: #666666">@</span> X_train<span style="color: #666666">.</span>T <span style="color: #666666">@</span> y_train
<span style="color: #008000">print</span>(OLSbeta)
<span style="color: #408080; font-style: italic"># and then make the prediction</span>
ytildeOLS <span style="color: #666666">=</span> X_train <span style="color: #666666">@</span> OLSbeta
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Training MSE for OLS&quot;</span>)
<span style="color: #008000">print</span>(MSE(y_train,ytildeOLS))
ypredictOLS <span style="color: #666666">=</span> X_test <span style="color: #666666">@</span> OLSbeta
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Test MSE OLS&quot;</span>)
<span style="color: #008000">print</span>(MSE(y_test,ypredictOLS))

p <span style="color: #666666">=</span> <span style="color: #008000">len</span>(OLSbeta)
I <span style="color: #666666">=</span> np<span style="color: #666666">.</span>eye(p,p)
<span style="color: #408080; font-style: italic"># Decide which values of lambda to use</span>
nlambdas <span style="color: #666666">=</span> <span style="color: #666666">4</span>
MSEOwnRidgePredict <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros(nlambdas)
MSEOwnRidgeTrain <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros(nlambdas)
MSERidgePredict <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros(nlambdas)
MSERidgeTrain <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros(nlambdas)

lambdas <span style="color: #666666">=</span> np<span style="color: #666666">.</span>logspace(<span style="color: #666666">-4</span>, <span style="color: #666666">4</span>, nlambdas)
<span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(nlambdas):
    lmb <span style="color: #666666">=</span> lambdas[i]
    OwnRidgeBeta <span style="color: #666666">=</span> np<span style="color: #666666">.</span>linalg<span style="color: #666666">.</span>pinv(X_train<span style="color: #666666">.</span>T <span style="color: #666666">@</span> X_train<span style="color: #666666">+</span>lmb<span style="color: #666666">*</span>I) <span style="color: #666666">@</span> X_train<span style="color: #666666">.</span>T <span style="color: #666666">@</span> y_train
    <span style="color: #408080; font-style: italic"># include lasso using Scikit-Learn</span>
    <span style="color: #408080; font-style: italic"># Note: we include the intercept</span>
    RegRidge <span style="color: #666666">=</span> linear_model<span style="color: #666666">.</span>Ridge(lmb,fit_intercept<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">False</span>)
    RegRidge<span style="color: #666666">.</span>fit(X_train,y_train)
    <span style="color: #408080; font-style: italic"># and then make the prediction</span>
    ytildeOwnRidge <span style="color: #666666">=</span> X_train <span style="color: #666666">@</span> OwnRidgeBeta
    ypredictOwnRidge <span style="color: #666666">=</span> X_test <span style="color: #666666">@</span> OwnRidgeBeta
    ytildeRidge <span style="color: #666666">=</span> RegRidge<span style="color: #666666">.</span>predict(X_train)
    ypredictRidge <span style="color: #666666">=</span> RegRidge<span style="color: #666666">.</span>predict(X_test)
    MSEOwnRidgePredict[i] <span style="color: #666666">=</span> MSE(y_test,ypredictOwnRidge)
    MSEOwnRidgeTrain[i] <span style="color: #666666">=</span> MSE(y_train,ytildeOwnRidge)
    MSERidgePredict[i] <span style="color: #666666">=</span> MSE(y_test,ypredictRidge)
    MSERidgeTrain[i] <span style="color: #666666">=</span> MSE(y_train,ytildeRidge)
    <span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Beta values for own Ridge implementation&quot;</span>)
    <span style="color: #008000">print</span>(OwnRidgeBeta)
    <span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Beta values for Scikit-Learn Ridge implementation&quot;</span>)
    <span style="color: #008000">print</span>(RegRidge<span style="color: #666666">.</span>coef_)
<span style="color: #408080; font-style: italic"># Now plot the results</span>
plt<span style="color: #666666">.</span>figure()
plt<span style="color: #666666">.</span>plot(np<span style="color: #666666">.</span>log10(lambdas), MSEOwnRidgeTrain, <span style="color: #BA2121">&#39;b&#39;</span>, label <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;MSE Ridge train&#39;</span>)
plt<span style="color: #666666">.</span>plot(np<span style="color: #666666">.</span>log10(lambdas), MSEOwnRidgePredict, <span style="color: #BA2121">&#39;r&#39;</span>, label <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;MSE Ridge Test&#39;</span>)
plt<span style="color: #666666">.</span>plot(np<span style="color: #666666">.</span>log10(lambdas), MSERidgeTrain, <span style="color: #BA2121">&#39;y&#39;</span>, label <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;MSE Ridge train&#39;</span>)
plt<span style="color: #666666">.</span>plot(np<span style="color: #666666">.</span>log10(lambdas), MSERidgePredict, <span style="color: #BA2121">&#39;g&#39;</span>, label <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;MSE Ridge Test&#39;</span>)

plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&#39;log10(lambda)&#39;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&#39;MSE&#39;</span>)
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()
</pre></div>
<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week38-bs006.html">&laquo;</a></li>
  <li><a href="._week38-bs000.html">1</a></li>
  <li><a href="._week38-bs001.html">2</a></li>
  <li><a href="._week38-bs002.html">3</a></li>
  <li><a href="._week38-bs003.html">4</a></li>
  <li><a href="._week38-bs004.html">5</a></li>
  <li><a href="._week38-bs005.html">6</a></li>
  <li><a href="._week38-bs006.html">7</a></li>
  <li class="active"><a href="._week38-bs007.html">8</a></li>
  <li><a href="._week38-bs008.html">9</a></li>
  <li><a href="._week38-bs009.html">10</a></li>
  <li><a href="._week38-bs010.html">11</a></li>
  <li><a href="._week38-bs011.html">12</a></li>
  <li><a href="._week38-bs012.html">13</a></li>
  <li><a href="._week38-bs013.html">14</a></li>
  <li><a href="._week38-bs014.html">15</a></li>
  <li><a href="._week38-bs015.html">16</a></li>
  <li><a href="._week38-bs016.html">17</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week38-bs038.html">39</a></li>
  <li><a href="._week38-bs008.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    

