<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week46.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week46-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 46: Support Vector Machines and Project 3. Start Principal Component Analysis">
<title>Week 46: Support Vector Machines and Project 3. Start Principal Component Analysis</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week46.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week46-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Overview of week 46', 2, None, 'overview-of-week-46'),
              ('Support Vector Machines, overarching aims',
               2,
               None,
               'support-vector-machines-overarching-aims'),
              ('Hyperplanes and all that', 2, None, 'hyperplanes-and-all-that'),
              ('What is a hyperplane?', 2, None, 'what-is-a-hyperplane'),
              ('A $p$-dimensional space of features',
               2,
               None,
               'a-p-dimensional-space-of-features'),
              ('The two-dimensional case', 2, None, 'the-two-dimensional-case'),
              ('Getting into the details', 2, None, 'getting-into-the-details'),
              ('First attempt at a minimization approach',
               2,
               None,
               'first-attempt-at-a-minimization-approach'),
              ('Solving the equations', 2, None, 'solving-the-equations'),
              ('Code Example', 2, None, 'code-example'),
              ('Problems with the Simpler Approach',
               2,
               None,
               'problems-with-the-simpler-approach'),
              ('A better approach', 2, None, 'a-better-approach'),
              ('A quick Reminder on Lagrangian Multipliers',
               2,
               None,
               'a-quick-reminder-on-lagrangian-multipliers'),
              ('Adding the Multiplier', 2, None, 'adding-the-multiplier'),
              ('Setting up the Problem', 2, None, 'setting-up-the-problem'),
              ('The problem to solve', 2, None, 'the-problem-to-solve'),
              ('The last steps', 2, None, 'the-last-steps'),
              ('A soft classifier', 2, None, 'a-soft-classifier'),
              ('Soft optmization problem', 2, None, 'soft-optmization-problem'),
              ('Kernels and non-linearity',
               2,
               None,
               'kernels-and-non-linearity'),
              ('The equations', 2, None, 'the-equations'),
              ('The problem to solve', 2, None, 'the-problem-to-solve'),
              ("Different kernels and Mercer's theorem",
               2,
               None,
               'different-kernels-and-mercer-s-theorem'),
              ('The moons example', 2, None, 'the-moons-example'),
              ('Mathematical optimization of convex functions',
               2,
               None,
               'mathematical-optimization-of-convex-functions'),
              ('How do we solve these problems?',
               2,
               None,
               'how-do-we-solve-these-problems'),
              ('A simple example', 2, None, 'a-simple-example'),
              ('Back to the more realistic cases',
               2,
               None,
               'back-to-the-more-realistic-cases'),
              ('Basic ideas of the Principal Component Analysis (PCA)',
               2,
               None,
               'basic-ideas-of-the-principal-component-analysis-pca'),
              ('Introducing the Covariance and Correlation functions',
               2,
               None,
               'introducing-the-covariance-and-correlation-functions'),
              ('More on the covariance', 2, None, 'more-on-the-covariance'),
              ('Reminding ourselves about Linear Regression',
               2,
               None,
               'reminding-ourselves-about-linear-regression'),
              ('Simple Example', 2, None, 'simple-example'),
              ('The Correlation Matrix', 2, None, 'the-correlation-matrix'),
              ('Numpy Functionality', 2, None, 'numpy-functionality'),
              ('Correlation Matrix again', 2, None, 'correlation-matrix-again'),
              ('Using Pandas', 2, None, 'using-pandas'),
              ('And then the Franke Function',
               2,
               None,
               'and-then-the-franke-function'),
              ('Links with the Design Matrix',
               2,
               None,
               'links-with-the-design-matrix'),
              ('Computing the Expectation Values',
               2,
               None,
               'computing-the-expectation-values'),
              ('Towards the PCA theorem', 2, None, 'towards-the-pca-theorem'),
              ('More on the PCA Theorem', 2, None, 'more-on-the-pca-theorem'),
              ('Writing our own PCA code', 2, None, 'writing-our-own-pca-code'),
              ('Implementing it', 2, None, 'implementing-it'),
              ('First Step', 2, None, 'first-step'),
              ('Scaling', 2, None, 'scaling'),
              ('Centered Data', 2, None, 'centered-data'),
              ('Exploring', 2, None, 'exploring'),
              ('Diagonalize the sample covariance matrix to obtain the '
               'principal components',
               2,
               None,
               'diagonalize-the-sample-covariance-matrix-to-obtain-the-principal-components'),
              ('Collecting all Steps', 2, None, 'collecting-all-steps'),
              ('Classical PCA Theorem', 2, None, 'classical-pca-theorem'),
              ('The PCA Theorem', 2, None, 'the-pca-theorem'),
              ('Geometric Interpretation and link with Singular Value '
               'Decomposition',
               2,
               None,
               'geometric-interpretation-and-link-with-singular-value-decomposition'),
              ('PCA and scikit-learn', 2, None, 'pca-and-scikit-learn'),
              ('Back to the Cancer Data', 2, None, 'back-to-the-cancer-data'),
              ('Incremental PCA', 2, None, 'incremental-pca'),
              ('Randomized PCA', 3, None, 'randomized-pca'),
              ('Kernel PCA', 3, None, 'kernel-pca'),
              ('Other techniques', 2, None, 'other-techniques')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week46-bs.html">Week 46: Support Vector Machines and Project 3. Start Principal Component Analysis</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week46-bs001.html#overview-of-week-46" style="font-size: 80%;"><b>Overview of week 46</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs002.html#support-vector-machines-overarching-aims" style="font-size: 80%;"><b>Support Vector Machines, overarching aims</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs003.html#hyperplanes-and-all-that" style="font-size: 80%;"><b>Hyperplanes and all that</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs004.html#what-is-a-hyperplane" style="font-size: 80%;"><b>What is a hyperplane?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs005.html#a-p-dimensional-space-of-features" style="font-size: 80%;"><b>A \( p \)-dimensional space of features</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs006.html#the-two-dimensional-case" style="font-size: 80%;"><b>The two-dimensional case</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs007.html#getting-into-the-details" style="font-size: 80%;"><b>Getting into the details</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs008.html#first-attempt-at-a-minimization-approach" style="font-size: 80%;"><b>First attempt at a minimization approach</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs009.html#solving-the-equations" style="font-size: 80%;"><b>Solving the equations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs010.html#code-example" style="font-size: 80%;"><b>Code Example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs011.html#problems-with-the-simpler-approach" style="font-size: 80%;"><b>Problems with the Simpler Approach</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs012.html#a-better-approach" style="font-size: 80%;"><b>A better approach</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs013.html#a-quick-reminder-on-lagrangian-multipliers" style="font-size: 80%;"><b>A quick Reminder on Lagrangian Multipliers</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs014.html#adding-the-multiplier" style="font-size: 80%;"><b>Adding the Multiplier</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs015.html#setting-up-the-problem" style="font-size: 80%;"><b>Setting up the Problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs022.html#the-problem-to-solve" style="font-size: 80%;"><b>The problem to solve</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs017.html#the-last-steps" style="font-size: 80%;"><b>The last steps</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs018.html#a-soft-classifier" style="font-size: 80%;"><b>A soft classifier</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs019.html#soft-optmization-problem" style="font-size: 80%;"><b>Soft optmization problem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs020.html#kernels-and-non-linearity" style="font-size: 80%;"><b>Kernels and non-linearity</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs021.html#the-equations" style="font-size: 80%;"><b>The equations</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs022.html#the-problem-to-solve" style="font-size: 80%;"><b>The problem to solve</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs023.html#different-kernels-and-mercer-s-theorem" style="font-size: 80%;"><b>Different kernels and Mercer's theorem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs024.html#the-moons-example" style="font-size: 80%;"><b>The moons example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs025.html#mathematical-optimization-of-convex-functions" style="font-size: 80%;"><b>Mathematical optimization of convex functions</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs026.html#how-do-we-solve-these-problems" style="font-size: 80%;"><b>How do we solve these problems?</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs027.html#a-simple-example" style="font-size: 80%;"><b>A simple example</b></a></li>
     <!-- navigation toc: --> <li><a href="#back-to-the-more-realistic-cases" style="font-size: 80%;"><b>Back to the more realistic cases</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs029.html#basic-ideas-of-the-principal-component-analysis-pca" style="font-size: 80%;"><b>Basic ideas of the Principal Component Analysis (PCA)</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs030.html#introducing-the-covariance-and-correlation-functions" style="font-size: 80%;"><b>Introducing the Covariance and Correlation functions</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs031.html#more-on-the-covariance" style="font-size: 80%;"><b>More on the covariance</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs032.html#reminding-ourselves-about-linear-regression" style="font-size: 80%;"><b>Reminding ourselves about Linear Regression</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs033.html#simple-example" style="font-size: 80%;"><b>Simple Example</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs034.html#the-correlation-matrix" style="font-size: 80%;"><b>The Correlation Matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs035.html#numpy-functionality" style="font-size: 80%;"><b>Numpy Functionality</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs036.html#correlation-matrix-again" style="font-size: 80%;"><b>Correlation Matrix again</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs037.html#using-pandas" style="font-size: 80%;"><b>Using Pandas</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs038.html#and-then-the-franke-function" style="font-size: 80%;"><b>And then the Franke Function</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs039.html#links-with-the-design-matrix" style="font-size: 80%;"><b>Links with the Design Matrix</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs040.html#computing-the-expectation-values" style="font-size: 80%;"><b>Computing the Expectation Values</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs041.html#towards-the-pca-theorem" style="font-size: 80%;"><b>Towards the PCA theorem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs042.html#more-on-the-pca-theorem" style="font-size: 80%;"><b>More on the PCA Theorem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs043.html#writing-our-own-pca-code" style="font-size: 80%;"><b>Writing our own PCA code</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs044.html#implementing-it" style="font-size: 80%;"><b>Implementing it</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs045.html#first-step" style="font-size: 80%;"><b>First Step</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs046.html#scaling" style="font-size: 80%;"><b>Scaling</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs047.html#centered-data" style="font-size: 80%;"><b>Centered Data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs048.html#exploring" style="font-size: 80%;"><b>Exploring</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs049.html#diagonalize-the-sample-covariance-matrix-to-obtain-the-principal-components" style="font-size: 80%;"><b>Diagonalize the sample covariance matrix to obtain the principal components</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs050.html#collecting-all-steps" style="font-size: 80%;"><b>Collecting all Steps</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs051.html#classical-pca-theorem" style="font-size: 80%;"><b>Classical PCA Theorem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs052.html#the-pca-theorem" style="font-size: 80%;"><b>The PCA Theorem</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs053.html#geometric-interpretation-and-link-with-singular-value-decomposition" style="font-size: 80%;"><b>Geometric Interpretation and link with Singular Value Decomposition</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs054.html#pca-and-scikit-learn" style="font-size: 80%;"><b>PCA and scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs055.html#back-to-the-cancer-data" style="font-size: 80%;"><b>Back to the Cancer Data</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs056.html#incremental-pca" style="font-size: 80%;"><b>Incremental PCA</b></a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs056.html#randomized-pca" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Randomized PCA</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs056.html#kernel-pca" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Kernel PCA</a></li>
     <!-- navigation toc: --> <li><a href="._week46-bs057.html#other-techniques" style="font-size: 80%;"><b>Other techniques</b></a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0028"></a>
<!-- !split -->
<h2 id="back-to-the-more-realistic-cases" class="anchor">Back to the more realistic cases </h2>

<p>We are now ready to return to our setup of the optmization problem for a more realistic case. Introducing the <b>slack</b> parameter \( C \) we have</p>
$$
\frac{1}{2} \boldsymbol{\lambda}^T\begin{bmatrix} y_1y_1K(\boldsymbol{x}_1,\boldsymbol{x}_1) & y_1y_2K(\boldsymbol{x}_1,\boldsymbol{x}_2) & \dots & \dots & y_1y_nK(\boldsymbol{x}_1,\boldsymbol{x}_n) \\
y_2y_1K(\boldsymbol{x}_2,\boldsymbol{x}_1) & y_2y_2K(\boldsymbol{x}_2,\boldsymbol{x}_2) & \dots & \dots & y_1y_nK(\boldsymbol{x}_2,\boldsymbol{x}_n) \\
\dots & \dots & \dots & \dots & \dots \\
\dots & \dots & \dots & \dots & \dots \\
y_ny_1K(\boldsymbol{x}_n,\boldsymbol{x}_1) & y_ny_2K(\boldsymbol{x}_n\boldsymbol{x}_2) & \dots & \dots & y_ny_nK(\boldsymbol{x}_n,\boldsymbol{x}_n) \\
\end{bmatrix}\boldsymbol{\lambda}-\mathbb{I}\boldsymbol{\lambda}, 
$$

<p>subject to \( \boldsymbol{y}^T\boldsymbol{\lambda}=0 \). Here we defined the vectors \( \boldsymbol{\lambda} =[\lambda_1,\lambda_2,\dots,\lambda_n] \) and 
\( \boldsymbol{y}=[y_1,y_2,\dots,y_n] \). 
With  the slack constants this leads to the additional constraint \( 0\leq \lambda_i \leq C \).
</p>

<p>Using the <b>CVXOPT</b> library, the matrix \( P \) would then be defined by the </p>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week46-bs027.html">&laquo;</a></li>
  <li><a href="._week46-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week46-bs020.html">21</a></li>
  <li><a href="._week46-bs021.html">22</a></li>
  <li><a href="._week46-bs022.html">23</a></li>
  <li><a href="._week46-bs023.html">24</a></li>
  <li><a href="._week46-bs024.html">25</a></li>
  <li><a href="._week46-bs025.html">26</a></li>
  <li><a href="._week46-bs026.html">27</a></li>
  <li><a href="._week46-bs027.html">28</a></li>
  <li class="active"><a href="._week46-bs028.html">29</a></li>
  <li><a href="._week46-bs029.html">30</a></li>
  <li><a href="._week46-bs030.html">31</a></li>
  <li><a href="._week46-bs031.html">32</a></li>
  <li><a href="._week46-bs032.html">33</a></li>
  <li><a href="._week46-bs033.html">34</a></li>
  <li><a href="._week46-bs034.html">35</a></li>
  <li><a href="._week46-bs035.html">36</a></li>
  <li><a href="._week46-bs036.html">37</a></li>
  <li><a href="._week46-bs037.html">38</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week46-bs057.html">58</a></li>
  <li><a href="._week46-bs029.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

