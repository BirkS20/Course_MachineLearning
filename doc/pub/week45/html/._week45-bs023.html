<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week45.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week45-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 45: Decisions Trees, Random Forests, Bagging  and Boosting">
<title>Week 45: Decisions Trees, Random Forests, Bagging  and Boosting</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week45.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week45-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Overview of week 45', 2, None, 'overview-of-week-45'),
              ('Brief code reminder from last wekk',
               2,
               None,
               'brief-code-reminder-from-last-wekk'),
              ("Boosting, a Bird's Eye View",
               2,
               None,
               'boosting-a-bird-s-eye-view'),
              ('What is boosting? Additive Modelling/Iterative Fitting',
               2,
               None,
               'what-is-boosting-additive-modelling-iterative-fitting'),
              ('Iterative Fitting, Regression and Squared-error Cost Function',
               2,
               None,
               'iterative-fitting-regression-and-squared-error-cost-function'),
              ('Squared-Error Example and Iterative Fitting',
               2,
               None,
               'squared-error-example-and-iterative-fitting'),
              ('Iterative Fitting, Classification and AdaBoost',
               2,
               None,
               'iterative-fitting-classification-and-adaboost'),
              ('Adaptive Boosting, AdaBoost',
               2,
               None,
               'adaptive-boosting-adaboost'),
              ('Building up AdaBoost', 2, None, 'building-up-adaboost'),
              ('Adaptive boosting: AdaBoost, Basic Algorithm',
               2,
               None,
               'adaptive-boosting-adaboost-basic-algorithm'),
              ('Basic Steps of AdaBoost', 2, None, 'basic-steps-of-adaboost'),
              ('AdaBoost Examples', 2, None, 'adaboost-examples'),
              ('Gradient boosting: Basics with Steepest Descent/Functional '
               'Gradient Descent',
               2,
               None,
               'gradient-boosting-basics-with-steepest-descent-functional-gradient-descent'),
              ('The Squared-Error again! Steepest Descent',
               2,
               None,
               'the-squared-error-again-steepest-descent'),
              ('Steepest Descent Example', 2, None, 'steepest-descent-example'),
              ('Gradient Boosting, algorithm',
               2,
               None,
               'gradient-boosting-algorithm'),
              ('Gradient Boosting, Examples of Regression',
               2,
               None,
               'gradient-boosting-examples-of-regression'),
              ('Gradient Boosting, Classification Example',
               2,
               None,
               'gradient-boosting-classification-example'),
              ('XGBoost: Extreme Gradient Boosting',
               2,
               None,
               'xgboost-extreme-gradient-boosting'),
              ('Regression Case', 2, None, 'regression-case'),
              ('Xgboost on the Cancer Data',
               2,
               None,
               'xgboost-on-the-cancer-data'),
              ('Support Vector Machines, overarching aims',
               2,
               None,
               'support-vector-machines-overarching-aims'),
              ('Hyperplanes and all that', 2, None, 'hyperplanes-and-all-that'),
              ('What is a hyperplane?', 2, None, 'what-is-a-hyperplane'),
              ('A $p$-dimensional space of features',
               2,
               None,
               'a-p-dimensional-space-of-features'),
              ('The two-dimensional case', 2, None, 'the-two-dimensional-case'),
              ('Getting into the details', 2, None, 'getting-into-the-details'),
              ('First attempt at a minimization approach',
               2,
               None,
               'first-attempt-at-a-minimization-approach'),
              ('Solving the equations', 2, None, 'solving-the-equations'),
              ('Code Example', 2, None, 'code-example'),
              ('Problems with the Simpler Approach',
               2,
               None,
               'problems-with-the-simpler-approach'),
              ('A better approach', 2, None, 'a-better-approach'),
              ('A quick Reminder on Lagrangian Multipliers',
               2,
               None,
               'a-quick-reminder-on-lagrangian-multipliers'),
              ('Adding the Multiplier', 2, None, 'adding-the-multiplier'),
              ('Setting up the Problem', 2, None, 'setting-up-the-problem'),
              ('The problem to solve', 2, None, 'the-problem-to-solve'),
              ('The last steps', 2, None, 'the-last-steps'),
              ('A soft classifier', 2, None, 'a-soft-classifier'),
              ('Soft optmization problem',
               2,
               None,
               'soft-optmization-problem')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week45-bs.html">Week 45: Decisions Trees, Random Forests, Bagging  and Boosting</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week45-bs001.html#overview-of-week-45" style="font-size: 80%;">Overview of week 45</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs002.html#brief-code-reminder-from-last-wekk" style="font-size: 80%;">Brief code reminder from last wekk</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs003.html#boosting-a-bird-s-eye-view" style="font-size: 80%;">Boosting, a Bird's Eye View</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs004.html#what-is-boosting-additive-modelling-iterative-fitting" style="font-size: 80%;">What is boosting? Additive Modelling/Iterative Fitting</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs005.html#iterative-fitting-regression-and-squared-error-cost-function" style="font-size: 80%;">Iterative Fitting, Regression and Squared-error Cost Function</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs006.html#squared-error-example-and-iterative-fitting" style="font-size: 80%;">Squared-Error Example and Iterative Fitting</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs007.html#iterative-fitting-classification-and-adaboost" style="font-size: 80%;">Iterative Fitting, Classification and AdaBoost</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs008.html#adaptive-boosting-adaboost" style="font-size: 80%;">Adaptive Boosting, AdaBoost</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs009.html#building-up-adaboost" style="font-size: 80%;">Building up AdaBoost</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs010.html#adaptive-boosting-adaboost-basic-algorithm" style="font-size: 80%;">Adaptive boosting: AdaBoost, Basic Algorithm</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs011.html#basic-steps-of-adaboost" style="font-size: 80%;">Basic Steps of AdaBoost</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs012.html#adaboost-examples" style="font-size: 80%;">AdaBoost Examples</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs013.html#gradient-boosting-basics-with-steepest-descent-functional-gradient-descent" style="font-size: 80%;">Gradient boosting: Basics with Steepest Descent/Functional Gradient Descent</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs014.html#the-squared-error-again-steepest-descent" style="font-size: 80%;">The Squared-Error again! Steepest Descent</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs015.html#steepest-descent-example" style="font-size: 80%;">Steepest Descent Example</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs016.html#gradient-boosting-algorithm" style="font-size: 80%;">Gradient Boosting, algorithm</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs017.html#gradient-boosting-examples-of-regression" style="font-size: 80%;">Gradient Boosting, Examples of Regression</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs018.html#gradient-boosting-classification-example" style="font-size: 80%;">Gradient Boosting, Classification Example</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs019.html#xgboost-extreme-gradient-boosting" style="font-size: 80%;">XGBoost: Extreme Gradient Boosting</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs020.html#regression-case" style="font-size: 80%;">Regression Case</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs021.html#xgboost-on-the-cancer-data" style="font-size: 80%;">Xgboost on the Cancer Data</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs022.html#support-vector-machines-overarching-aims" style="font-size: 80%;">Support Vector Machines, overarching aims</a></li>
     <!-- navigation toc: --> <li><a href="#hyperplanes-and-all-that" style="font-size: 80%;">Hyperplanes and all that</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs024.html#what-is-a-hyperplane" style="font-size: 80%;">What is a hyperplane?</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs025.html#a-p-dimensional-space-of-features" style="font-size: 80%;">A \( p \)-dimensional space of features</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs026.html#the-two-dimensional-case" style="font-size: 80%;">The two-dimensional case</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs027.html#getting-into-the-details" style="font-size: 80%;">Getting into the details</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs028.html#first-attempt-at-a-minimization-approach" style="font-size: 80%;">First attempt at a minimization approach</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs029.html#solving-the-equations" style="font-size: 80%;">Solving the equations</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs030.html#code-example" style="font-size: 80%;">Code Example</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs031.html#problems-with-the-simpler-approach" style="font-size: 80%;">Problems with the Simpler Approach</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs032.html#a-better-approach" style="font-size: 80%;">A better approach</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs033.html#a-quick-reminder-on-lagrangian-multipliers" style="font-size: 80%;">A quick Reminder on Lagrangian Multipliers</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs034.html#adding-the-multiplier" style="font-size: 80%;">Adding the Multiplier</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs035.html#setting-up-the-problem" style="font-size: 80%;">Setting up the Problem</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs036.html#the-problem-to-solve" style="font-size: 80%;">The problem to solve</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs037.html#the-last-steps" style="font-size: 80%;">The last steps</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs038.html#a-soft-classifier" style="font-size: 80%;">A soft classifier</a></li>
     <!-- navigation toc: --> <li><a href="._week45-bs039.html#soft-optmization-problem" style="font-size: 80%;">Soft optmization problem</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0023"></a>
<!-- !split -->
<h2 id="hyperplanes-and-all-that" class="anchor">Hyperplanes and all that </h2>

<p>The theory behind support vector machines (SVM hereafter) is based on
the mathematical description of so-called hyperplanes. Let us start
with a two-dimensional case. This will also allow us to introduce our
first SVM examples. These will be tailored to the case of two specific
classes, as displayed in the figure here based on the usage of the petal data.
</p>

<p>We assume here that our data set can be well separated into two
domains, where a straight line does the job in the separating the two
classes. Here the two classes are represented by either squares or
circles.
</p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn</span> <span style="color: #008000; font-weight: bold">import</span> datasets
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.svm</span> <span style="color: #008000; font-weight: bold">import</span> SVC, LinearSVC
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.linear_model</span> <span style="color: #008000; font-weight: bold">import</span> SGDClassifier
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.preprocessing</span> <span style="color: #008000; font-weight: bold">import</span> StandardScaler
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
plt<span style="color: #666666">.</span>rcParams[<span style="color: #BA2121">&#39;axes.labelsize&#39;</span>] <span style="color: #666666">=</span> <span style="color: #666666">14</span>
plt<span style="color: #666666">.</span>rcParams[<span style="color: #BA2121">&#39;xtick.labelsize&#39;</span>] <span style="color: #666666">=</span> <span style="color: #666666">12</span>
plt<span style="color: #666666">.</span>rcParams[<span style="color: #BA2121">&#39;ytick.labelsize&#39;</span>] <span style="color: #666666">=</span> <span style="color: #666666">12</span>


iris <span style="color: #666666">=</span> datasets<span style="color: #666666">.</span>load_iris()
X <span style="color: #666666">=</span> iris[<span style="color: #BA2121">&quot;data&quot;</span>][:, (<span style="color: #666666">2</span>, <span style="color: #666666">3</span>)]  <span style="color: #408080; font-style: italic"># petal length, petal width</span>
y <span style="color: #666666">=</span> iris[<span style="color: #BA2121">&quot;target&quot;</span>]

setosa_or_versicolor <span style="color: #666666">=</span> (y <span style="color: #666666">==</span> <span style="color: #666666">0</span>) <span style="color: #666666">|</span> (y <span style="color: #666666">==</span> <span style="color: #666666">1</span>)
X <span style="color: #666666">=</span> X[setosa_or_versicolor]
y <span style="color: #666666">=</span> y[setosa_or_versicolor]



C <span style="color: #666666">=</span> <span style="color: #666666">5</span>
alpha <span style="color: #666666">=</span> <span style="color: #666666">1</span> <span style="color: #666666">/</span> (C <span style="color: #666666">*</span> <span style="color: #008000">len</span>(X))

lin_clf <span style="color: #666666">=</span> LinearSVC(loss<span style="color: #666666">=</span><span style="color: #BA2121">&quot;hinge&quot;</span>, C<span style="color: #666666">=</span>C, random_state<span style="color: #666666">=42</span>)
svm_clf <span style="color: #666666">=</span> SVC(kernel<span style="color: #666666">=</span><span style="color: #BA2121">&quot;linear&quot;</span>, C<span style="color: #666666">=</span>C)
sgd_clf <span style="color: #666666">=</span> SGDClassifier(loss<span style="color: #666666">=</span><span style="color: #BA2121">&quot;hinge&quot;</span>, learning_rate<span style="color: #666666">=</span><span style="color: #BA2121">&quot;constant&quot;</span>, eta0<span style="color: #666666">=0.001</span>, alpha<span style="color: #666666">=</span>alpha,
                        max_iter<span style="color: #666666">=100000</span>, random_state<span style="color: #666666">=42</span>)

scaler <span style="color: #666666">=</span> StandardScaler()
X_scaled <span style="color: #666666">=</span> scaler<span style="color: #666666">.</span>fit_transform(X)

lin_clf<span style="color: #666666">.</span>fit(X_scaled, y)
svm_clf<span style="color: #666666">.</span>fit(X_scaled, y)
sgd_clf<span style="color: #666666">.</span>fit(X_scaled, y)

<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;LinearSVC:                   &quot;</span>, lin_clf<span style="color: #666666">.</span>intercept_, lin_clf<span style="color: #666666">.</span>coef_)
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;SVC:                         &quot;</span>, svm_clf<span style="color: #666666">.</span>intercept_, svm_clf<span style="color: #666666">.</span>coef_)
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;SGDClassifier(alpha=</span><span style="color: #BB6688; font-weight: bold">{:.5f}</span><span style="color: #BA2121">):&quot;</span><span style="color: #666666">.</span>format(sgd_clf<span style="color: #666666">.</span>alpha), sgd_clf<span style="color: #666666">.</span>intercept_, sgd_clf<span style="color: #666666">.</span>coef_)

<span style="color: #408080; font-style: italic"># Compute the slope and bias of each decision boundary</span>
w1 <span style="color: #666666">=</span> <span style="color: #666666">-</span>lin_clf<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">0</span>]<span style="color: #666666">/</span>lin_clf<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">1</span>]
b1 <span style="color: #666666">=</span> <span style="color: #666666">-</span>lin_clf<span style="color: #666666">.</span>intercept_[<span style="color: #666666">0</span>]<span style="color: #666666">/</span>lin_clf<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">1</span>]
w2 <span style="color: #666666">=</span> <span style="color: #666666">-</span>svm_clf<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">0</span>]<span style="color: #666666">/</span>svm_clf<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">1</span>]
b2 <span style="color: #666666">=</span> <span style="color: #666666">-</span>svm_clf<span style="color: #666666">.</span>intercept_[<span style="color: #666666">0</span>]<span style="color: #666666">/</span>svm_clf<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">1</span>]
w3 <span style="color: #666666">=</span> <span style="color: #666666">-</span>sgd_clf<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">0</span>]<span style="color: #666666">/</span>sgd_clf<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">1</span>]
b3 <span style="color: #666666">=</span> <span style="color: #666666">-</span>sgd_clf<span style="color: #666666">.</span>intercept_[<span style="color: #666666">0</span>]<span style="color: #666666">/</span>sgd_clf<span style="color: #666666">.</span>coef_[<span style="color: #666666">0</span>, <span style="color: #666666">1</span>]

<span style="color: #408080; font-style: italic"># Transform the decision boundary lines back to the original scale</span>
line1 <span style="color: #666666">=</span> scaler<span style="color: #666666">.</span>inverse_transform([[<span style="color: #666666">-10</span>, <span style="color: #666666">-10</span> <span style="color: #666666">*</span> w1 <span style="color: #666666">+</span> b1], [<span style="color: #666666">10</span>, <span style="color: #666666">10</span> <span style="color: #666666">*</span> w1 <span style="color: #666666">+</span> b1]])
line2 <span style="color: #666666">=</span> scaler<span style="color: #666666">.</span>inverse_transform([[<span style="color: #666666">-10</span>, <span style="color: #666666">-10</span> <span style="color: #666666">*</span> w2 <span style="color: #666666">+</span> b2], [<span style="color: #666666">10</span>, <span style="color: #666666">10</span> <span style="color: #666666">*</span> w2 <span style="color: #666666">+</span> b2]])
line3 <span style="color: #666666">=</span> scaler<span style="color: #666666">.</span>inverse_transform([[<span style="color: #666666">-10</span>, <span style="color: #666666">-10</span> <span style="color: #666666">*</span> w3 <span style="color: #666666">+</span> b3], [<span style="color: #666666">10</span>, <span style="color: #666666">10</span> <span style="color: #666666">*</span> w3 <span style="color: #666666">+</span> b3]])

<span style="color: #408080; font-style: italic"># Plot all three decision boundaries</span>
plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">11</span>, <span style="color: #666666">4</span>))
plt<span style="color: #666666">.</span>plot(line1[:, <span style="color: #666666">0</span>], line1[:, <span style="color: #666666">1</span>], <span style="color: #BA2121">&quot;k:&quot;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;LinearSVC&quot;</span>)
plt<span style="color: #666666">.</span>plot(line2[:, <span style="color: #666666">0</span>], line2[:, <span style="color: #666666">1</span>], <span style="color: #BA2121">&quot;b--&quot;</span>, linewidth<span style="color: #666666">=2</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;SVC&quot;</span>)
plt<span style="color: #666666">.</span>plot(line3[:, <span style="color: #666666">0</span>], line3[:, <span style="color: #666666">1</span>], <span style="color: #BA2121">&quot;r-&quot;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;SGDClassifier&quot;</span>)
plt<span style="color: #666666">.</span>plot(X[:, <span style="color: #666666">0</span>][y<span style="color: #666666">==1</span>], X[:, <span style="color: #666666">1</span>][y<span style="color: #666666">==1</span>], <span style="color: #BA2121">&quot;bs&quot;</span>) <span style="color: #408080; font-style: italic"># label=&quot;Iris-Versicolor&quot;</span>
plt<span style="color: #666666">.</span>plot(X[:, <span style="color: #666666">0</span>][y<span style="color: #666666">==0</span>], X[:, <span style="color: #666666">1</span>][y<span style="color: #666666">==0</span>], <span style="color: #BA2121">&quot;yo&quot;</span>) <span style="color: #408080; font-style: italic"># label=&quot;Iris-Setosa&quot;</span>
plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&quot;Petal length&quot;</span>, fontsize<span style="color: #666666">=14</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&quot;Petal width&quot;</span>, fontsize<span style="color: #666666">=14</span>)
plt<span style="color: #666666">.</span>legend(loc<span style="color: #666666">=</span><span style="color: #BA2121">&quot;upper center&quot;</span>, fontsize<span style="color: #666666">=14</span>)
plt<span style="color: #666666">.</span>axis([<span style="color: #666666">0</span>, <span style="color: #666666">5.5</span>, <span style="color: #666666">0</span>, <span style="color: #666666">2</span>])

plt<span style="color: #666666">.</span>show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week45-bs022.html">&laquo;</a></li>
  <li><a href="._week45-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week45-bs015.html">16</a></li>
  <li><a href="._week45-bs016.html">17</a></li>
  <li><a href="._week45-bs017.html">18</a></li>
  <li><a href="._week45-bs018.html">19</a></li>
  <li><a href="._week45-bs019.html">20</a></li>
  <li><a href="._week45-bs020.html">21</a></li>
  <li><a href="._week45-bs021.html">22</a></li>
  <li><a href="._week45-bs022.html">23</a></li>
  <li class="active"><a href="._week45-bs023.html">24</a></li>
  <li><a href="._week45-bs024.html">25</a></li>
  <li><a href="._week45-bs025.html">26</a></li>
  <li><a href="._week45-bs026.html">27</a></li>
  <li><a href="._week45-bs027.html">28</a></li>
  <li><a href="._week45-bs028.html">29</a></li>
  <li><a href="._week45-bs029.html">30</a></li>
  <li><a href="._week45-bs030.html">31</a></li>
  <li><a href="._week45-bs031.html">32</a></li>
  <li><a href="._week45-bs032.html">33</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week45-bs039.html">40</a></li>
  <li><a href="._week45-bs024.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

