<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 44: From Decision Trees to Bagging methods">

<title>Week 44: From Decision Trees to Bagging methods</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Overview of week 44', 2, None, '___sec0'),
              ('Thursday', 2, None, '___sec1'),
              ('Decision trees, overarching aims', 2, None, '___sec2'),
              ('Basics of a tree', 2, None, '___sec3'),
              ('A Sketch of a Tree, Regression problem', 2, None, '___sec4'),
              ('A Sketch of a Tree, Classification  problem',
               2,
               None,
               '___sec5'),
              ('A typical Decision Tree with its pertinent Jargon, '
               'Classification Problem',
               2,
               None,
               '___sec6'),
              ('General Features', 2, None, '___sec7'),
              ('How do we set it up?', 2, None, '___sec8'),
              ('Decision trees and Regression', 2, None, '___sec9'),
              ('Building a tree, regression', 2, None, '___sec10'),
              ('A top-down approach, recursive binary splitting',
               2,
               None,
               '___sec11'),
              ('Making a tree', 2, None, '___sec12'),
              ('Pruning the tree', 2, None, '___sec13'),
              ('Cost complexity pruning', 2, None, '___sec14'),
              ('Schematic Regression Procedure', 2, None, '___sec15'),
              ('A Classification Tree', 2, None, '___sec16'),
              ('Growing a classification tree', 2, None, '___sec17'),
              ('Classification tree, how to split nodes', 2, None, '___sec18'),
              ('Visualizing the Tree, Classification', 2, None, '___sec19'),
              ('Visualizing the Tree, The Moons', 2, None, '___sec20'),
              ('Other ways of visualizing the trees', 2, None, '___sec21'),
              ('Printing out as text', 2, None, '___sec22'),
              ('Algorithms for Setting up Decision Trees', 2, None, '___sec23'),
              ('The CART algorithm for Classification', 2, None, '___sec24'),
              ('The CART algorithm for Regression', 2, None, '___sec25'),
              ('Computing the Gini index', 2, None, '___sec26'),
              ('Simple Python Code to read in Data and perform Classification',
               2,
               None,
               '___sec27'),
              ('Computing the Gini Factor', 2, None, '___sec28'),
              ('Entropy and the ID3 algorithm', 2, None, '___sec29'),
              ('Cancer Data again now with Decision Trees and other Methods',
               2,
               None,
               '___sec30'),
              ('Another example, the moons again', 2, None, '___sec31'),
              ('Playing around with regions', 2, None, '___sec32'),
              ('Regression trees', 2, None, '___sec33'),
              ('Final regressor code', 2, None, '___sec34'),
              ('Pros and cons of trees, pros', 2, None, '___sec35'),
              ('Disadvantages', 2, None, '___sec36'),
              ('Ensemble Methods: From a Single Tree to Many Trees and Extreme '
               'Boosting, Meet the Jungle of Methods',
               2,
               None,
               '___sec37'),
              ('An Overview of Ensemble Methods', 2, None, '___sec38'),
              ('Bagging', 2, None, '___sec39'),
              ('More bagging', 2, None, '___sec40'),
              ('Simple Voting Example, head or tail', 2, None, '___sec41'),
              ('Using the Voting Classifier', 2, None, '___sec42'),
              ('Please, not the moons again! Voting and Bagging',
               2,
               None,
               '___sec43'),
              ('Bagging Examples', 2, None, '___sec44'),
              ('Making your own Bootstrap: Changing the Level of the Decision '
               'Tree',
               2,
               None,
               '___sec45')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week44-bs.html">Week 44: From Decision Trees to Bagging methods</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week44-bs001.html#___sec0" style="font-size: 80%;">Overview of week 44</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs002.html#___sec1" style="font-size: 80%;">Thursday</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs003.html#___sec2" style="font-size: 80%;">Decision trees, overarching aims</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs004.html#___sec3" style="font-size: 80%;">Basics of a tree</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs005.html#___sec4" style="font-size: 80%;">A Sketch of a Tree, Regression problem</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs006.html#___sec5" style="font-size: 80%;">A Sketch of a Tree, Classification  problem</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs007.html#___sec6" style="font-size: 80%;">A typical Decision Tree with its pertinent Jargon, Classification Problem</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs008.html#___sec7" style="font-size: 80%;">General Features</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs009.html#___sec8" style="font-size: 80%;">How do we set it up?</a></li>
     <!-- navigation toc: --> <li><a href="#___sec9" style="font-size: 80%;">Decision trees and Regression</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs011.html#___sec10" style="font-size: 80%;">Building a tree, regression</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs012.html#___sec11" style="font-size: 80%;">A top-down approach, recursive binary splitting</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs013.html#___sec12" style="font-size: 80%;">Making a tree</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs014.html#___sec13" style="font-size: 80%;">Pruning the tree</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs015.html#___sec14" style="font-size: 80%;">Cost complexity pruning</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs016.html#___sec15" style="font-size: 80%;">Schematic Regression Procedure</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs017.html#___sec16" style="font-size: 80%;">A Classification Tree</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs018.html#___sec17" style="font-size: 80%;">Growing a classification tree</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs019.html#___sec18" style="font-size: 80%;">Classification tree, how to split nodes</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs020.html#___sec19" style="font-size: 80%;">Visualizing the Tree, Classification</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs021.html#___sec20" style="font-size: 80%;">Visualizing the Tree, The Moons</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs022.html#___sec21" style="font-size: 80%;">Other ways of visualizing the trees</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs023.html#___sec22" style="font-size: 80%;">Printing out as text</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs024.html#___sec23" style="font-size: 80%;">Algorithms for Setting up Decision Trees</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs025.html#___sec24" style="font-size: 80%;">The CART algorithm for Classification</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs026.html#___sec25" style="font-size: 80%;">The CART algorithm for Regression</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs027.html#___sec26" style="font-size: 80%;">Computing the Gini index</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs028.html#___sec27" style="font-size: 80%;">Simple Python Code to read in Data and perform Classification</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs029.html#___sec28" style="font-size: 80%;">Computing the Gini Factor</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs030.html#___sec29" style="font-size: 80%;">Entropy and the ID3 algorithm</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs031.html#___sec30" style="font-size: 80%;">Cancer Data again now with Decision Trees and other Methods</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs032.html#___sec31" style="font-size: 80%;">Another example, the moons again</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs033.html#___sec32" style="font-size: 80%;">Playing around with regions</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs034.html#___sec33" style="font-size: 80%;">Regression trees</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs035.html#___sec34" style="font-size: 80%;">Final regressor code</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs036.html#___sec35" style="font-size: 80%;">Pros and cons of trees, pros</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs037.html#___sec36" style="font-size: 80%;">Disadvantages</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs038.html#___sec37" style="font-size: 80%;">Ensemble Methods: From a Single Tree to Many Trees and Extreme Boosting, Meet the Jungle of Methods</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs039.html#___sec38" style="font-size: 80%;">An Overview of Ensemble Methods</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs040.html#___sec39" style="font-size: 80%;">Bagging</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs041.html#___sec40" style="font-size: 80%;">More bagging</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs042.html#___sec41" style="font-size: 80%;">Simple Voting Example, head or tail</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs043.html#___sec42" style="font-size: 80%;">Using the Voting Classifier</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs044.html#___sec43" style="font-size: 80%;">Please, not the moons again! Voting and Bagging</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs045.html#___sec44" style="font-size: 80%;">Bagging Examples</a></li>
     <!-- navigation toc: --> <li><a href="._week44-bs046.html#___sec45" style="font-size: 80%;">Making your own Bootstrap: Changing the Level of the Decision Tree</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0010"></a>
<!-- !split -->

<h2 id="___sec9" class="anchor">Decision trees and Regression  </h2>
<p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="highlight" style="background: #f8f8f8"><pre style="line-height: 125%"><span></span><span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.preprocessing</span> <span style="color: #008000; font-weight: bold">import</span> PolynomialFeatures
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.linear_model</span> <span style="color: #008000; font-weight: bold">import</span> LinearRegression

steps<span style="color: #666666">=250</span>

distance<span style="color: #666666">=0</span>
x<span style="color: #666666">=0</span>
distance_list<span style="color: #666666">=</span>[]
steps_list<span style="color: #666666">=</span>[]
<span style="color: #008000; font-weight: bold">while</span> x<span style="color: #666666">&lt;</span>steps:
    distance<span style="color: #666666">+=</span>np<span style="color: #666666">.</span>random<span style="color: #666666">.</span>randint(<span style="color: #666666">-1</span>,<span style="color: #666666">2</span>)
    distance_list<span style="color: #666666">.</span>append(distance)
    x<span style="color: #666666">+=1</span>
    steps_list<span style="color: #666666">.</span>append(x)
plt<span style="color: #666666">.</span>plot(steps_list,distance_list, color<span style="color: #666666">=</span><span style="color: #BA2121">&#39;green&#39;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;Random Walk Data&quot;</span>)

steps_list<span style="color: #666666">=</span>np<span style="color: #666666">.</span>asarray(steps_list)
distance_list<span style="color: #666666">=</span>np<span style="color: #666666">.</span>asarray(distance_list)

X<span style="color: #666666">=</span>steps_list[:,np<span style="color: #666666">.</span>newaxis]

<span style="color: #408080; font-style: italic">#Polynomial fits</span>

<span style="color: #408080; font-style: italic">#Degree 2</span>
poly_features<span style="color: #666666">=</span>PolynomialFeatures(degree<span style="color: #666666">=2</span>, include_bias<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">False</span>)
X_poly<span style="color: #666666">=</span>poly_features<span style="color: #666666">.</span>fit_transform(X)

lin_reg<span style="color: #666666">=</span>LinearRegression()
poly_fit<span style="color: #666666">=</span>lin_reg<span style="color: #666666">.</span>fit(X_poly,distance_list)
b<span style="color: #666666">=</span>lin_reg<span style="color: #666666">.</span>coef_
c<span style="color: #666666">=</span>lin_reg<span style="color: #666666">.</span>intercept_
<span style="color: #008000">print</span> (<span style="color: #BA2121">&quot;2nd degree coefficients:&quot;</span>)
<span style="color: #008000">print</span> (<span style="color: #BA2121">&quot;zero power: &quot;</span>,c)
<span style="color: #008000">print</span> (<span style="color: #BA2121">&quot;first power: &quot;</span>, b[<span style="color: #666666">0</span>])
<span style="color: #008000">print</span> (<span style="color: #BA2121">&quot;second power: &quot;</span>,b[<span style="color: #666666">1</span>])

z <span style="color: #666666">=</span> np<span style="color: #666666">.</span>arange(<span style="color: #666666">0</span>, steps, <span style="color: #666666">.01</span>)
z_mod<span style="color: #666666">=</span>b[<span style="color: #666666">1</span>]<span style="color: #666666">*</span>z<span style="color: #666666">**2+</span>b[<span style="color: #666666">0</span>]<span style="color: #666666">*</span>z<span style="color: #666666">+</span>c

fit_mod<span style="color: #666666">=</span>b[<span style="color: #666666">1</span>]<span style="color: #666666">*</span>X<span style="color: #666666">**2+</span>b[<span style="color: #666666">0</span>]<span style="color: #666666">*</span>X<span style="color: #666666">+</span>c
plt<span style="color: #666666">.</span>plot(z, z_mod, color<span style="color: #666666">=</span><span style="color: #BA2121">&#39;r&#39;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;2nd Degree Fit&quot;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&quot;Polynomial Regression&quot;</span>)

plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&quot;Steps&quot;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&quot;Distance&quot;</span>)

<span style="color: #408080; font-style: italic">#Degree 10</span>
poly_features10<span style="color: #666666">=</span>PolynomialFeatures(degree<span style="color: #666666">=10</span>, include_bias<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">False</span>)
X_poly10<span style="color: #666666">=</span>poly_features10<span style="color: #666666">.</span>fit_transform(X)

poly_fit10<span style="color: #666666">=</span>lin_reg<span style="color: #666666">.</span>fit(X_poly10,distance_list)

y_plot<span style="color: #666666">=</span>poly_fit10<span style="color: #666666">.</span>predict(X_poly10)
plt<span style="color: #666666">.</span>plot(X, y_plot, color<span style="color: #666666">=</span><span style="color: #BA2121">&#39;black&#39;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;10th Degree Fit&quot;</span>)

plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()


<span style="color: #408080; font-style: italic">#Decision Tree Regression</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.tree</span> <span style="color: #008000; font-weight: bold">import</span> DecisionTreeRegressor
regr_1<span style="color: #666666">=</span>DecisionTreeRegressor(max_depth<span style="color: #666666">=2</span>)
regr_2<span style="color: #666666">=</span>DecisionTreeRegressor(max_depth<span style="color: #666666">=5</span>)
regr_3<span style="color: #666666">=</span>DecisionTreeRegressor(max_depth<span style="color: #666666">=7</span>)
regr_1<span style="color: #666666">.</span>fit(X, distance_list)
regr_2<span style="color: #666666">.</span>fit(X, distance_list)
regr_3<span style="color: #666666">.</span>fit(X, distance_list)

X_test <span style="color: #666666">=</span> np<span style="color: #666666">.</span>arange(<span style="color: #666666">0.0</span>, steps, <span style="color: #666666">0.01</span>)[:, np<span style="color: #666666">.</span>newaxis]
y_1 <span style="color: #666666">=</span> regr_1<span style="color: #666666">.</span>predict(X_test)
y_2 <span style="color: #666666">=</span> regr_2<span style="color: #666666">.</span>predict(X_test)
y_3<span style="color: #666666">=</span>regr_3<span style="color: #666666">.</span>predict(X_test)

<span style="color: #408080; font-style: italic"># Plot the results</span>
plt<span style="color: #666666">.</span>figure()
plt<span style="color: #666666">.</span>scatter(X, distance_list, s<span style="color: #666666">=2.5</span>, c<span style="color: #666666">=</span><span style="color: #BA2121">&quot;black&quot;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;data&quot;</span>)
plt<span style="color: #666666">.</span>plot(X_test, y_1, color<span style="color: #666666">=</span><span style="color: #BA2121">&quot;red&quot;</span>,
         label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;max_depth=2&quot;</span>, linewidth<span style="color: #666666">=2</span>)
plt<span style="color: #666666">.</span>plot(X_test, y_2, color<span style="color: #666666">=</span><span style="color: #BA2121">&quot;green&quot;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;max_depth=5&quot;</span>, linewidth<span style="color: #666666">=2</span>)
plt<span style="color: #666666">.</span>plot(X_test, y_3, color<span style="color: #666666">=</span><span style="color: #BA2121">&quot;m&quot;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;max_depth=7&quot;</span>, linewidth<span style="color: #666666">=2</span>)

plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&quot;Data&quot;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&quot;Darget&quot;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&quot;Decision Tree Regression&quot;</span>)
plt<span style="color: #666666">.</span>legend()
plt<span style="color: #666666">.</span>show()
</pre></div>
<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week44-bs009.html">&laquo;</a></li>
  <li><a href="._week44-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week44-bs002.html">3</a></li>
  <li><a href="._week44-bs003.html">4</a></li>
  <li><a href="._week44-bs004.html">5</a></li>
  <li><a href="._week44-bs005.html">6</a></li>
  <li><a href="._week44-bs006.html">7</a></li>
  <li><a href="._week44-bs007.html">8</a></li>
  <li><a href="._week44-bs008.html">9</a></li>
  <li><a href="._week44-bs009.html">10</a></li>
  <li class="active"><a href="._week44-bs010.html">11</a></li>
  <li><a href="._week44-bs011.html">12</a></li>
  <li><a href="._week44-bs012.html">13</a></li>
  <li><a href="._week44-bs013.html">14</a></li>
  <li><a href="._week44-bs014.html">15</a></li>
  <li><a href="._week44-bs015.html">16</a></li>
  <li><a href="._week44-bs016.html">17</a></li>
  <li><a href="._week44-bs017.html">18</a></li>
  <li><a href="._week44-bs018.html">19</a></li>
  <li><a href="._week44-bs019.html">20</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week44-bs046.html">47</a></li>
  <li><a href="._week44-bs011.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    

