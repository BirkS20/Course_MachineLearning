<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 42 Convolutional and Recurrent Neural Networks and Autoencoders">

<title>Week 42 Convolutional and Recurrent Neural Networks and Autoencoders</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 42', 2, None, '___sec0'),
              ('Convolutional Neural Networks (recognizing images)',
               2,
               None,
               '___sec1'),
              ('Regular NNs don’t scale well to full images',
               2,
               None,
               '___sec2'),
              ('3D volumes of neurons', 2, None, '___sec3'),
              ('Layers used to build CNNs', 2, None, '___sec4'),
              ('Transforming images', 2, None, '___sec5'),
              ('CNNs in brief', 2, None, '___sec6'),
              ('CNNs in more detail, building convolutional neural networks in '
               'Tensorflow and Keras',
               2,
               None,
               '___sec7'),
              ('Setting it up', 2, None, '___sec8'),
              ('The MNIST dataset again', 2, None, '___sec9'),
              ('Strong correlations', 2, None, '___sec10'),
              ('Layers of a CNN', 2, None, '___sec11'),
              ('Systematic reduction', 2, None, '___sec12'),
              ('Prerequisites: Collect and pre-process data',
               2,
               None,
               '___sec13'),
              ('Importing Keras and Tensorflow', 2, None, '___sec14'),
              ('Running with Keras', 2, None, '___sec15'),
              ('Final part', 2, None, '___sec16'),
              ('Final visualization', 2, None, '___sec17'),
              ('The CIFAR01 data set', 2, None, '___sec18'),
              ('Verifying the data set', 2, None, '___sec19'),
              ('Set up  the model', 2, None, '___sec20'),
              ('Add Dense layers on top', 2, None, '___sec21'),
              ('Compile and train the model', 2, None, '___sec22'),
              ('Finally, evaluate the model', 2, None, '___sec23'),
              ('Recurrent neural networks: Overarching view',
               2,
               None,
               '___sec24'),
              ('Set up of an RNN', 2, None, '___sec25'),
              ('Solving differential equations and eigenvalue problems with '
               'RNNs',
               2,
               None,
               '___sec26'),
              ('Long-Short Time Memory', 2, None, '___sec27'),
              ('Autoencoders: Overarching view', 2, None, '___sec28'),
              ('Simple examples of Autoencoders', 2, None, '___sec29')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week42-bs.html">Week 42 Convolutional and Recurrent Neural Networks and Autoencoders</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week42-bs001.html#___sec0" style="font-size: 80%;">Plan for week 42</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs002.html#___sec1" style="font-size: 80%;">Convolutional Neural Networks (recognizing images)</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs003.html#___sec2" style="font-size: 80%;">Regular NNs don’t scale well to full images</a></li>
     <!-- navigation toc: --> <li><a href="#___sec3" style="font-size: 80%;">3D volumes of neurons</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs005.html#___sec4" style="font-size: 80%;">Layers used to build CNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs006.html#___sec5" style="font-size: 80%;">Transforming images</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs007.html#___sec6" style="font-size: 80%;">CNNs in brief</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs008.html#___sec7" style="font-size: 80%;">CNNs in more detail, building convolutional neural networks in Tensorflow and Keras</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs009.html#___sec8" style="font-size: 80%;">Setting it up</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs010.html#___sec9" style="font-size: 80%;">The MNIST dataset again</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs011.html#___sec10" style="font-size: 80%;">Strong correlations</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs012.html#___sec11" style="font-size: 80%;">Layers of a CNN</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs013.html#___sec12" style="font-size: 80%;">Systematic reduction</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs014.html#___sec13" style="font-size: 80%;">Prerequisites: Collect and pre-process data</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs015.html#___sec14" style="font-size: 80%;">Importing Keras and Tensorflow</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs016.html#___sec15" style="font-size: 80%;">Running with Keras</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs017.html#___sec16" style="font-size: 80%;">Final part</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs018.html#___sec17" style="font-size: 80%;">Final visualization</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs019.html#___sec18" style="font-size: 80%;">The CIFAR01 data set</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs020.html#___sec19" style="font-size: 80%;">Verifying the data set</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs021.html#___sec20" style="font-size: 80%;">Set up  the model</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs022.html#___sec21" style="font-size: 80%;">Add Dense layers on top</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs023.html#___sec22" style="font-size: 80%;">Compile and train the model</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs024.html#___sec23" style="font-size: 80%;">Finally, evaluate the model</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs025.html#___sec24" style="font-size: 80%;">Recurrent neural networks: Overarching view</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs026.html#___sec25" style="font-size: 80%;">Set up of an RNN</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs027.html#___sec26" style="font-size: 80%;">Solving differential equations and eigenvalue problems with RNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs028.html#___sec27" style="font-size: 80%;">Long-Short Time Memory</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs029.html#___sec28" style="font-size: 80%;">Autoencoders: Overarching view</a></li>
     <!-- navigation toc: --> <li><a href="._week42-bs030.html#___sec29" style="font-size: 80%;">Simple examples of Autoencoders</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0004"></a>
<!-- !split -->

<h2 id="___sec3" class="anchor">3D volumes of neurons </h2>

<p>
Convolutional Neural Networks take advantage of the fact that the
input consists of images and they constrain the architecture in a more
sensible way.

<p>
In particular, unlike a regular Neural Network, the
layers of a CNN have neurons arranged in 3 dimensions: width,
height, depth. (Note that the word depth here refers to the third
dimension of an activation volume, not to the depth of a full Neural
Network, which can refer to the total number of layers in a network.)

<p>
To understand it better, the above example of an image 
with an input volume of
activations has dimensions \( 32\times 32\times 3 \) (width, height,
depth respectively).

<p>
The neurons in a layer will
only be connected to a small region of the layer before it, instead of
all of the neurons in a fully-connected manner. Moreover, the final
output layer could  for this specific image have dimensions \( 1\times 1 \times 10 \), 
because by the
end of the CNN architecture we will reduce the full image into a
single vector of class scores, arranged along the depth
dimension.

<p>
<center>  <!-- FIGURE -->
<hr class="figure">
<center><p class="caption">Figure 2:  A CNN arranges its neurons in three dimensions (width, height, depth), as visualized in one of the layers. Every layer of a CNN transforms the 3D input volume to a 3D output volume of neuron activations. In this example, the red input layer holds the image, so its width and height would be the dimensions of the image, and the depth would be 3 (Red, Green, Blue channels). </p></center>
<p><img src="figslides/cnn.jpeg" align="bottom" width=500></p>
</center>

<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week42-bs003.html">&laquo;</a></li>
  <li><a href="._week42-bs000.html">1</a></li>
  <li><a href="._week42-bs001.html">2</a></li>
  <li><a href="._week42-bs002.html">3</a></li>
  <li><a href="._week42-bs003.html">4</a></li>
  <li class="active"><a href="._week42-bs004.html">5</a></li>
  <li><a href="._week42-bs005.html">6</a></li>
  <li><a href="._week42-bs006.html">7</a></li>
  <li><a href="._week42-bs007.html">8</a></li>
  <li><a href="._week42-bs008.html">9</a></li>
  <li><a href="._week42-bs009.html">10</a></li>
  <li><a href="._week42-bs010.html">11</a></li>
  <li><a href="._week42-bs011.html">12</a></li>
  <li><a href="._week42-bs012.html">13</a></li>
  <li><a href="._week42-bs013.html">14</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week42-bs030.html">31</a></li>
  <li><a href="._week42-bs005.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>


</body>
</html>
    

