<!--
Automatically generated HTML file from DocOnce source
(https://github.com/doconce/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Week 39: Optimization and  Gradient Methods">

<title>Week 39: Optimization and  Gradient Methods</title>

<!-- Bootstrap style: bootstrap -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">

/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}

/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>


</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 39', 2, None, 'plan-for-week-39'),
              ('Thursday September 30', 2, None, 'thursday-september-30'),
              ('Searching for Optimal Regularization Parameters $\\lambda$',
               2,
               None,
               'searching-for-optimal-regularization-parameters-lambda'),
              ('Grid Search', 2, None, 'grid-search'),
              ('Randomized Grid Search', 2, None, 'randomized-grid-search'),
              ('Optimization, the central part of any Machine Learning '
               'algortithm',
               2,
               None,
               'optimization-the-central-part-of-any-machine-learning-algortithm'),
              ('Revisiting our Logistic Regression case',
               2,
               None,
               'revisiting-our-logistic-regression-case'),
              ('The equations to solve', 2, None, 'the-equations-to-solve'),
              ("Solving using Newton-Raphson's method",
               2,
               None,
               'solving-using-newton-raphson-s-method'),
              ("Brief reminder on Newton-Raphson's method",
               2,
               None,
               'brief-reminder-on-newton-raphson-s-method'),
              ('The equations', 2, None, 'the-equations'),
              ('Simple geometric interpretation',
               2,
               None,
               'simple-geometric-interpretation'),
              ('Extending to more than one variable',
               2,
               None,
               'extending-to-more-than-one-variable'),
              ('Steepest descent', 2, None, 'steepest-descent'),
              ('More on Steepest descent', 2, None, 'more-on-steepest-descent'),
              ('The ideal', 2, None, 'the-ideal'),
              ('The sensitiveness of the gradient descent',
               2,
               None,
               'the-sensitiveness-of-the-gradient-descent'),
              ('Convex functions', 2, None, 'convex-functions'),
              ('Convex function', 2, None, 'convex-function'),
              ('Conditions on convex functions',
               2,
               None,
               'conditions-on-convex-functions'),
              ('More on convex functions', 2, None, 'more-on-convex-functions'),
              ('Some simple problems', 2, None, 'some-simple-problems'),
              ('Standard steepest descent',
               2,
               None,
               'standard-steepest-descent'),
              ('Gradient method', 2, None, 'gradient-method'),
              ('Steepest descent  method', 2, None, 'steepest-descent-method'),
              ('Steepest descent  method', 2, None, 'steepest-descent-method'),
              ('Final expressions', 2, None, 'final-expressions'),
              ('Steepest descent example', 2, None, 'steepest-descent-example'),
              ('Conjugate gradient method',
               2,
               None,
               'conjugate-gradient-method'),
              ('Conjugate gradient method',
               2,
               None,
               'conjugate-gradient-method'),
              ('Conjugate gradient method',
               2,
               None,
               'conjugate-gradient-method'),
              ('Conjugate gradient method',
               2,
               None,
               'conjugate-gradient-method'),
              ('Conjugate gradient method and iterations',
               2,
               None,
               'conjugate-gradient-method-and-iterations'),
              ('Conjugate gradient method',
               2,
               None,
               'conjugate-gradient-method'),
              ('Conjugate gradient method',
               2,
               None,
               'conjugate-gradient-method'),
              ('Conjugate gradient method',
               2,
               None,
               'conjugate-gradient-method'),
              ('Revisiting our first homework',
               2,
               None,
               'revisiting-our-first-homework'),
              ('Gradient descent example', 2, None, 'gradient-descent-example'),
              ('The derivative of the cost/loss function',
               2,
               None,
               'the-derivative-of-the-cost-loss-function'),
              ('The Hessian matrix', 2, None, 'the-hessian-matrix'),
              ('Simple program', 2, None, 'simple-program'),
              ('Gradient Descent Example', 2, None, 'gradient-descent-example'),
              ('And a corresponding example using _scikit-learn_',
               2,
               None,
               'and-a-corresponding-example-using-_scikit-learn_'),
              ('Gradient descent and Ridge',
               2,
               None,
               'gradient-descent-and-ridge'),
              ('Program example for gradient descent with Ridge Regression',
               2,
               None,
               'program-example-for-gradient-descent-with-ridge-regression'),
              ('Using gradient descent methods, limitations',
               2,
               None,
               'using-gradient-descent-methods-limitations'),
              ('Friday October  1', 2, None, 'friday-october-1'),
              ('Stochastic Gradient Descent',
               2,
               None,
               'stochastic-gradient-descent'),
              ('Computation of gradients', 2, None, 'computation-of-gradients'),
              ('SGD example', 2, None, 'sgd-example'),
              ('The gradient step', 2, None, 'the-gradient-step'),
              ('Simple example code', 2, None, 'simple-example-code'),
              ('When do we stop?', 2, None, 'when-do-we-stop'),
              ('Slightly different approach',
               2,
               None,
               'slightly-different-approach'),
              ('Program for stochastic gradient',
               2,
               None,
               'program-for-stochastic-gradient')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week39-bs.html">Week 39: Optimization and  Gradient Methods</a>
  </div>

  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week39-bs001.html#plan-for-week-39" style="font-size: 80%;">Plan for week 39</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs002.html#thursday-september-30" style="font-size: 80%;">Thursday September 30</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs003.html#searching-for-optimal-regularization-parameters-lambda" style="font-size: 80%;">Searching for Optimal Regularization Parameters \( \lambda \)</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs004.html#grid-search" style="font-size: 80%;">Grid Search</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs005.html#randomized-grid-search" style="font-size: 80%;">Randomized Grid Search</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs006.html#optimization-the-central-part-of-any-machine-learning-algortithm" style="font-size: 80%;">Optimization, the central part of any Machine Learning algortithm</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs007.html#revisiting-our-logistic-regression-case" style="font-size: 80%;">Revisiting our Logistic Regression case</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs008.html#the-equations-to-solve" style="font-size: 80%;">The equations to solve</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs009.html#solving-using-newton-raphson-s-method" style="font-size: 80%;">Solving using Newton-Raphson's method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs010.html#brief-reminder-on-newton-raphson-s-method" style="font-size: 80%;">Brief reminder on Newton-Raphson's method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs011.html#the-equations" style="font-size: 80%;">The equations</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs012.html#simple-geometric-interpretation" style="font-size: 80%;">Simple geometric interpretation</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs013.html#extending-to-more-than-one-variable" style="font-size: 80%;">Extending to more than one variable</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs014.html#steepest-descent" style="font-size: 80%;">Steepest descent</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs015.html#more-on-steepest-descent" style="font-size: 80%;">More on Steepest descent</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs016.html#the-ideal" style="font-size: 80%;">The ideal</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs017.html#the-sensitiveness-of-the-gradient-descent" style="font-size: 80%;">The sensitiveness of the gradient descent</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs018.html#convex-functions" style="font-size: 80%;">Convex functions</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs019.html#convex-function" style="font-size: 80%;">Convex function</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs020.html#conditions-on-convex-functions" style="font-size: 80%;">Conditions on convex functions</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs021.html#more-on-convex-functions" style="font-size: 80%;">More on convex functions</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs022.html#some-simple-problems" style="font-size: 80%;">Some simple problems</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs023.html#standard-steepest-descent" style="font-size: 80%;">Standard steepest descent</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs024.html#gradient-method" style="font-size: 80%;">Gradient method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs026.html#steepest-descent-method" style="font-size: 80%;">Steepest descent  method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs026.html#steepest-descent-method" style="font-size: 80%;">Steepest descent  method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs027.html#final-expressions" style="font-size: 80%;">Final expressions</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs028.html#steepest-descent-example" style="font-size: 80%;">Steepest descent example</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs036.html#conjugate-gradient-method" style="font-size: 80%;">Conjugate gradient method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs036.html#conjugate-gradient-method" style="font-size: 80%;">Conjugate gradient method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs036.html#conjugate-gradient-method" style="font-size: 80%;">Conjugate gradient method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs036.html#conjugate-gradient-method" style="font-size: 80%;">Conjugate gradient method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs033.html#conjugate-gradient-method-and-iterations" style="font-size: 80%;">Conjugate gradient method and iterations</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs036.html#conjugate-gradient-method" style="font-size: 80%;">Conjugate gradient method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs036.html#conjugate-gradient-method" style="font-size: 80%;">Conjugate gradient method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs036.html#conjugate-gradient-method" style="font-size: 80%;">Conjugate gradient method</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs037.html#revisiting-our-first-homework" style="font-size: 80%;">Revisiting our first homework</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs042.html#gradient-descent-example" style="font-size: 80%;">Gradient descent example</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs039.html#the-derivative-of-the-cost-loss-function" style="font-size: 80%;">The derivative of the cost/loss function</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs040.html#the-hessian-matrix" style="font-size: 80%;">The Hessian matrix</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs041.html#simple-program" style="font-size: 80%;">Simple program</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs042.html#gradient-descent-example" style="font-size: 80%;">Gradient Descent Example</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs043.html#and-a-corresponding-example-using-_scikit-learn_" style="font-size: 80%;">And a corresponding example using <b>scikit-learn</b></a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs044.html#gradient-descent-and-ridge" style="font-size: 80%;">Gradient descent and Ridge</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs045.html#program-example-for-gradient-descent-with-ridge-regression" style="font-size: 80%;">Program example for gradient descent with Ridge Regression</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs046.html#using-gradient-descent-methods-limitations" style="font-size: 80%;">Using gradient descent methods, limitations</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs047.html#friday-october-1" style="font-size: 80%;">Friday October  1</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs048.html#stochastic-gradient-descent" style="font-size: 80%;">Stochastic Gradient Descent</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs049.html#computation-of-gradients" style="font-size: 80%;">Computation of gradients</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs050.html#sgd-example" style="font-size: 80%;">SGD example</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs051.html#the-gradient-step" style="font-size: 80%;">The gradient step</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs052.html#simple-example-code" style="font-size: 80%;">Simple example code</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs053.html#when-do-we-stop" style="font-size: 80%;">When do we stop?</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs054.html#slightly-different-approach" style="font-size: 80%;">Slightly different approach</a></li>
     <!-- navigation toc: --> <li><a href="._week39-bs055.html#program-for-stochastic-gradient" style="font-size: 80%;">Program for stochastic gradient</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0000"></a>
<!-- ------------------- main content ---------------------- -->



<div class="jumbotron">
<center><h1>Week 39: Optimization and  Gradient Methods</h1></center>  <!-- document title -->

<p>
<!-- author(s): Morten Hjorth-Jensen -->

<center>
<b>Morten Hjorth-Jensen</b> [1, 2]
</center>

<p>
<!-- institution(s) -->

<center>[1] <b>Department of Physics, University of Oslo</b></center>
<center>[2] <b>Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University</b></center>
<br>
<p>
<center><h4>Sep 28, 2021</h4></center> <!-- date -->
<br>
<p>


<p><a href="._week39-bs001.html" class="btn btn-primary btn-lg">Read &raquo;</a></p>


</div> <!-- end jumbotron -->

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
  <li class="active"><a href="._week39-bs000.html">1</a></li>
  <li><a href="._week39-bs001.html">2</a></li>
  <li><a href="._week39-bs002.html">3</a></li>
  <li><a href="._week39-bs003.html">4</a></li>
  <li><a href="._week39-bs004.html">5</a></li>
  <li><a href="._week39-bs005.html">6</a></li>
  <li><a href="._week39-bs006.html">7</a></li>
  <li><a href="._week39-bs007.html">8</a></li>
  <li><a href="._week39-bs008.html">9</a></li>
  <li><a href="._week39-bs009.html">10</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week39-bs055.html">56</a></li>
  <li><a href="._week39-bs001.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->


<center style="font-size:80%">
<!-- copyright --> &copy; 1999-2021, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license
</center>


</body>
</html>
    

